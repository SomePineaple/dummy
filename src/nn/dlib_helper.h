//
// Created by nj60 on 11/24/25.
//

#ifndef DUMMY_DLIB_HELPER_H
#define DUMMY_DLIB_HELPER_H

#include <dlib/dnn.h>
#include <random>

namespace rummy::nn::nn_helper {
    // Generated by chatgpt
    template <typename NetType>
    void mutate_network(shared_ptr<NetType> net, const float mutationStrength, const float mutationChance) {
        dlib::rand rnd;

        // Visit all computational layers (layers with parameters/forward ops).
        dlib::visit_computational_layers(*net, [&](auto& layer)
        {
            // layer is the layer_details object (e.g. con_, fc_, layer_norm_, ...).
            auto& params = layer.get_layer_params();  // dlib::tensor [web:44][web:63]

            // Layers without parameters (or uninitialized params) just have size 0.
            if (params.size() == 0)
                return;

            // Work on host memory; dlib::tensor is iterable over floats. [web:63]
            float* data = params.host();
            for (size_t i = 0; i < params.size(); ++i)
            {
                if (rnd.get_double_in_range(0.0, 1.0) < mutationChance)
                    data[i] += mutationStrength * static_cast<float>(rnd.get_random_gaussian());
            }

            // If using CUDA, mark updated host data so it can be copied to device. [web:63] not needed for now.
            //params.async_copy_to_device();
        });
    }
}

#endif //DUMMY_DLIB_HELPER_H
